{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "conn = sqlite3.connect(\"../db/baltasar.db\")\n",
    "def sql(query):\n",
    "    #print(query)\n",
    "    return pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = ['type', 'operator', 'age', 'activeness', 'yield', 'parents', 'children', 'holdingSize', 'numberOfTokens']\n",
    "\n",
    "def getTokenPrices(startDate, endDate):\n",
    "    return sql('''SELECT\n",
    "                endPrice.token, \n",
    "                CASE\n",
    "                    WHEN endPrice.price / prevPrice.price > 1.5 THEN \"FLUC\"\n",
    "                    WHEN endPrice.price / prevPrice.price <= 0.67 THEN \"FLUC\"\n",
    "                    ELSE \"ORDINARY\"\n",
    "                END as success,\n",
    "                endPrice.price / prevPrice.price as valueChange\n",
    "            FROM\n",
    "                Price endPrice\n",
    "                INNER JOIN\n",
    "                Price prevPrice\n",
    "                ON endPrice.token = prevPrice.token\n",
    "            WHERE\n",
    "                prevPrice.date='''+str(taxonomyDate)+''' and\n",
    "                endPrice.date=''' + str(endDate))\n",
    "               \n",
    "def getOwnershipDistributionPerDimension(dimension, table='currentTaxonomyResults'):\n",
    "    grouped = sql('''SELECT \n",
    "        '''+dimension+ ''' as dimension,\n",
    "        token,\n",
    "        sum(percTokens) as percToken\n",
    "        FROM\n",
    "            '''+table+'''\n",
    "        GROUP BY token, '''+dimension\n",
    "       )\n",
    "    grouped['dimension'] = grouped['dimension'].apply(lambda c: dimension[:2]+\"_\"+c)\n",
    "    grouped = pd.pivot_table(grouped, values='percToken', index=['token'],\n",
    "                     columns=['dimension'], aggfunc=np.sum)\n",
    "    return grouped\n",
    "\n",
    "def makeDataSet(table, startDate, endDate):\n",
    "    tokens = getTokenPrices(startDate, endDate)\n",
    "    tokens = tokens.set_index('token')\n",
    "    # single columns\n",
    "    for dimension in dimensions:\n",
    "        grouped = getOwnershipDistributionPerDimension(dimension, table)\n",
    "        tokens = tokens.join(grouped)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomyDate = int(float(sql('''\n",
    "SELECT timestamp FROM Etransfer\n",
    "WHERE blocknumber=(SELECT max(blocknumber) FROM EntityTaxonomy)\n",
    "LIMIT 1''')['timestamp'][0]) / 86400) * 86400\n",
    "endDate = sql('''SELECT max(date) as d FROM Price''')['d'][0]\n",
    "\n",
    "trainDate_start = int(float(sql('''SELECT timestamp FROM ETransfer WHERE blocknumber=7020000''')['timestamp'][0]) / 86400) * 86400\n",
    "trainDate_end = trainDate_start + 118 * 86400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = makeDataSet('FormerTaxonomyResults', trainDate_start, trainDate_end)\n",
    "train['success'] = 'ORDINARY'\n",
    "train.loc[train['valueChange'] < train['valueChange'].quantile(0.25), 'success'] = 'FLUC'\n",
    "train.loc[train['valueChange'] >= train['valueChange'].quantile(0.75), 'success'] = 'FLUC'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>operator</th>\n",
       "      <th>age</th>\n",
       "      <th>activeness</th>\n",
       "      <th>yield</th>\n",
       "      <th>parents</th>\n",
       "      <th>children</th>\n",
       "      <th>holdingSize</th>\n",
       "      <th>numberOfTokens</th>\n",
       "      <th>token</th>\n",
       "      <th>numAddresses</th>\n",
       "      <th>percTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concentrator</td>\n",
       "      <td>capp</td>\n",
       "      <td>over1Year</td>\n",
       "      <td>daily</td>\n",
       "      <td>loss&lt;.9</td>\n",
       "      <td>diverse</td>\n",
       "      <td>diverse</td>\n",
       "      <td>over_1kkUSD</td>\n",
       "      <td>&gt;30</td>\n",
       "      <td>0xbtc</td>\n",
       "      <td>1</td>\n",
       "      <td>2.450236e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           type operator        age activeness    yield  parents children  \\\n",
       "0  concentrator     capp  over1Year      daily  loss<.9  diverse  diverse   \n",
       "\n",
       "   holdingSize numberOfTokens  token  numAddresses    percTokens  \n",
       "0  over_1kkUSD            >30  0xbtc             1  2.450236e-10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for (i in range(len(dimensions)):\n",
    "    for (j in range(len(i,dimensions)):\n",
    "        dimensionA = dimensions[i]\n",
    "        dimensionB = dimensions[j]\n",
    "        if dimensionA == dimensionB:\n",
    "            continue\n",
    "        grouped = data[['token', dimensionA, dimensionB,'percToken']].groupby(['token', dimensionA, dimensionB]).sum().reset_index()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(train['success'])\n",
    "y = np.array(labels)\n",
    "train = train.fillna(0)\n",
    "features = train.drop(['success','valueChange'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "scaler = StandardScaler()\n",
    "#data = tokens.values()\n",
    "scaler.fit(features)\n",
    "X = scaler.transform(features)\n",
    "clf = RandomForestClassifier(n_estimators=10000,\n",
    "                              max_depth=None, min_samples_split=2, max_features=\"sqrt\")\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: ty_connector_complex Importance: 0.02\n",
      "Variable: ty_connector_simple  Importance: 0.02\n",
      "Variable: ty_exchange          Importance: 0.02\n",
      "Variable: ty_mixer             Importance: 0.02\n",
      "Variable: ty_sink_simple       Importance: 0.02\n",
      "Variable: op_capp              Importance: 0.02\n",
      "Variable: op_other             Importance: 0.02\n",
      "Variable: ag_month             Importance: 0.02\n",
      "Variable: ag_quarter           Importance: 0.02\n",
      "Variable: ag_week              Importance: 0.02\n",
      "Variable: ag_year              Importance: 0.02\n",
      "Variable: ac_daily             Importance: 0.02\n",
      "Variable: ac_monthly           Importance: 0.02\n",
      "Variable: yi_loss<.67          Importance: 0.02\n",
      "Variable: yi_loss<.9           Importance: 0.02\n",
      "Variable: yi_profit<1.5        Importance: 0.02\n",
      "Variable: yi_profit<10         Importance: 0.02\n",
      "Variable: yi_steady>=.9,<1.1   Importance: 0.02\n",
      "Variable: pa_connector_complex Importance: 0.02\n",
      "Variable: pa_connector_simple  Importance: 0.02\n",
      "Variable: pa_dilluter          Importance: 0.02\n",
      "Variable: pa_exchange          Importance: 0.02\n",
      "Variable: pa_ico               Importance: 0.02\n",
      "Variable: pa_mixer             Importance: 0.02\n",
      "Variable: ch_connector_simple  Importance: 0.02\n",
      "Variable: ch_diverse           Importance: 0.02\n",
      "Variable: ch_ico               Importance: 0.02\n",
      "Variable: ch_mixer             Importance: 0.02\n",
      "Variable: ch_sink_simple       Importance: 0.02\n",
      "Variable: ho_origin            Importance: 0.02\n",
      "Variable: ho_over_1kkUSD       Importance: 0.02\n",
      "Variable: ho_under_100USD      Importance: 0.02\n",
      "Variable: ho_under_10USD       Importance: 0.02\n",
      "Variable: ho_under_10kUSD      Importance: 0.02\n",
      "Variable: ho_under_1USD        Importance: 0.02\n",
      "Variable: ho_under_1kUSD       Importance: 0.02\n",
      "Variable: ho_under_1kkUSD      Importance: 0.02\n",
      "Variable: nu_2                 Importance: 0.02\n",
      "Variable: nu_3-6               Importance: 0.02\n",
      "Variable: nu_6-30              Importance: 0.02\n",
      "Variable: nu_>30               Importance: 0.02\n",
      "Variable: ty_concentrator      Importance: 0.01\n",
      "Variable: ty_dilluter          Importance: 0.01\n",
      "Variable: ty_ico               Importance: 0.01\n",
      "Variable: ty_n/a               Importance: 0.01\n",
      "Variable: ty_sink_complex      Importance: 0.01\n",
      "Variable: ag_over1Year         Importance: 0.01\n",
      "Variable: ag_unknown           Importance: 0.01\n",
      "Variable: ac_inactive_empty    Importance: 0.01\n",
      "Variable: ac_inactive_not empty Importance: 0.01\n",
      "Variable: ac_weekly            Importance: 0.01\n",
      "Variable: yi_loss<.1           Importance: 0.01\n",
      "Variable: yi_profit>=10        Importance: 0.01\n",
      "Variable: yi_unknown           Importance: 0.01\n",
      "Variable: pa_concentrator      Importance: 0.01\n",
      "Variable: pa_diverse           Importance: 0.01\n",
      "Variable: pa_source            Importance: 0.01\n",
      "Variable: ch_concentrator      Importance: 0.01\n",
      "Variable: ch_connector_complex Importance: 0.01\n",
      "Variable: ch_dilluter          Importance: 0.01\n",
      "Variable: ch_exchange          Importance: 0.01\n",
      "Variable: ch_none              Importance: 0.01\n",
      "Variable: ch_sink_complex      Importance: 0.01\n",
      "Variable: ho_empty             Importance: 0.01\n",
      "Variable: nu_1                 Importance: 0.01\n",
      "Variable: nu_NONE              Importance: 0.01\n",
      "Variable: ty_source            Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(clf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = makeDataSet('CurrentTaxonomyResults', taxonomyDate, endDate)\n",
    "test['success'] = 'ORDINARY'\n",
    "\n",
    "test.loc[test['valueChange'] < test['valueChange'].quantile(0.25), 'success'] = 'FLUC'\n",
    "test.loc[test['valueChange'] >= test['valueChange'].quantile(0.75), 'success'] = 'FLUC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             success prediction  prediction_proba\n",
      "token                                                            \n",
      "sharpay                     ORDINARY   ORDINARY            0.0722\n",
      "hyperion                        FLUC   ORDINARY            0.0808\n",
      "xovbank                         FLUC   ORDINARY            0.0894\n",
      "acute-angle-cloud           ORDINARY   ORDINARY            0.0950\n",
      "stockchain                      FLUC   ORDINARY            0.0953\n",
      "decentraland                ORDINARY   ORDINARY            0.0975\n",
      "kucoin-shares                   FLUC   ORDINARY            0.0991\n",
      "jibrel-network              ORDINARY   ORDINARY            0.1078\n",
      "iostoken                    ORDINARY   ORDINARY            0.1098\n",
      "optitoken                   ORDINARY   ORDINARY            0.1103\n",
      "streamr-datacoin            ORDINARY   ORDINARY            0.1108\n",
      "smartmesh                   ORDINARY   ORDINARY            0.1111\n",
      "ubcoin-market               ORDINARY   ORDINARY            0.1123\n",
      "kyber-network               ORDINARY   ORDINARY            0.1154\n",
      "globalvillage-ecosystem     ORDINARY   ORDINARY            0.1178\n",
      "wandx                       ORDINARY   ORDINARY            0.1201\n",
      "latoken                     ORDINARY   ORDINARY            0.1211\n",
      "sense                       ORDINARY   ORDINARY            0.1225\n",
      "qurito                      ORDINARY   ORDINARY            0.1240\n",
      "esdchain                        FLUC   ORDINARY            0.1246\n",
      "singularitynet              ORDINARY   ORDINARY            0.1253\n",
      "content-neutrality-network  ORDINARY   ORDINARY            0.1255\n",
      "robotina                    ORDINARY   ORDINARY            0.1263\n",
      "pumapay                     ORDINARY   ORDINARY            0.1267\n",
      "chimpion                        FLUC   ORDINARY            0.1272\n",
      "eosdac                      ORDINARY   ORDINARY            0.1278\n",
      "boltt-coin                      FLUC   ORDINARY            0.1292\n",
      "hydro-protocol                  FLUC   ORDINARY            0.1293\n",
      "firstblood                      FLUC   ORDINARY            0.1297\n",
      "mithril-ore                     FLUC   ORDINARY            0.1306\n",
      "...                              ...        ...               ...\n",
      "okb                             FLUC       FLUC            0.8622\n",
      "vestchain                   ORDINARY       FLUC            0.8628\n",
      "vslice                      ORDINARY       FLUC            0.8630\n",
      "devery                      ORDINARY       FLUC            0.8659\n",
      "mindol                          FLUC       FLUC            0.8661\n",
      "crypto-harbor-exchange      ORDINARY       FLUC            0.8668\n",
      "1irstcoin                       FLUC       FLUC            0.8675\n",
      "dropil                      ORDINARY       FLUC            0.8676\n",
      "ezoow                       ORDINARY       FLUC            0.8676\n",
      "coni                        ORDINARY       FLUC            0.8687\n",
      "japan-content-token             FLUC       FLUC            0.8705\n",
      "dragonglass                 ORDINARY       FLUC            0.8707\n",
      "cmitcoin                        FLUC       FLUC            0.8712\n",
      "maverick-chain                  FLUC       FLUC            0.8719\n",
      "lisk-machine-learning           FLUC       FLUC            0.8722\n",
      "wrapped-bitcoin                 FLUC       FLUC            0.8732\n",
      "seele                           FLUC       FLUC            0.8749\n",
      "cotrader                        FLUC       FLUC            0.8751\n",
      "measurable-data-token       ORDINARY       FLUC            0.8754\n",
      "bee-token                       FLUC       FLUC            0.8761\n",
      "waltonchain                 ORDINARY       FLUC            0.8761\n",
      "pkg-token                   ORDINARY       FLUC            0.8764\n",
      "free-coin                   ORDINARY       FLUC            0.8777\n",
      "eventchain                      FLUC       FLUC            0.8793\n",
      "merculet                        FLUC       FLUC            0.8809\n",
      "power-ledger                ORDINARY       FLUC            0.8809\n",
      "gmb                         ORDINARY       FLUC            0.8860\n",
      "propy                       ORDINARY       FLUC            0.8884\n",
      "biotron                         FLUC       FLUC            0.8945\n",
      "skychain                        FLUC       FLUC            0.8955\n",
      "\n",
      "[973 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[248, 239],\n",
       "       [239, 247]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(test['success'])\n",
    "y = np.array(labels)\n",
    "train = train.fillna(0)\n",
    "features = train.drop(['success','valueChange'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features= np.array(features)\n",
    "X_test = scaler.transform(features)\n",
    "\n",
    "\n",
    "\n",
    "test['prediction_proba'] = clf.predict_proba(X_test)[:,0]\n",
    "test['prediction'] = clf.predict(X_test)\n",
    "print(test[['success', 'prediction', 'prediction_proba']].sort_values(by='prediction_proba'))\n",
    "\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(np.array(test['prediction']), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.23121237804299072, 0.6306263220153304, 1, array([[243.75025694, 243.24974306],\n",
      "       [243.24974306, 242.75025694]]))\n",
      "[[248 239]\n",
      " [239 247]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency \n",
    "\n",
    "#test_safe = test\n",
    "\n",
    "obs = confusion_matrix(np.array(test['prediction']), np.array(test['success']))\n",
    "#print(test_safe[['prediction', 'success', 'prediction_proba']])\n",
    "print(chi2_contingency(obs))\n",
    "print(obs)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
